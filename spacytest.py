#!/usr/bin/env python3
"""
spaCy Model Recommendation for Aspire Support Chatbot
Analyzes requirements and recommends the best model
"""

import spacy
from pathlib import Path

def analyze_chatbot_requirements():
    """Analyze the specific NLP requirements of the Aspire Support chatbot"""
    
    print("ğŸ” Analyzing Aspire Support Chatbot Requirements")
    print("=" * 60)
    
    requirements = {
        "Primary Tasks": [
            "ğŸ¯ Abend code extraction (S0C4, S0C7, S322, etc.)",
            "ğŸ’¬ Greeting detection (hello, hi, good morning)",
            "ğŸ”§ Technical term recognition",
            "ğŸ“ Intent classification support",
            "ğŸ” Entity extraction for production support"
        ],
        "Text Types": [
            "ğŸ“± Short user queries (5-50 words)",
            "ğŸ’» Technical mainframe terminology", 
            "ğŸ—£ï¸ Conversational language",
            "ğŸ“Š Error messages and codes",
            "â“ Question-answer pairs"
        ],
        "Performance Needs": [
            "âš¡ Real-time response (< 1 second)",
            "ğŸ’¾ Memory efficient (web deployment)",
            "ğŸ”„ High throughput (multiple users)",
            "ğŸ“¦ Small deployment size"
        ],
        "Accuracy Needs": [
            "ğŸ¯ High precision for abend codes (critical)",
            "ğŸ’¬ Good conversational understanding",
            "ğŸ” Reliable entity extraction",
            "ğŸ“ Consistent text processing"
        ]
    }
    
    for category, items in requirements.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  {item}")
    
    return requirements

def compare_spacy_models():
    """Compare different spaCy models for the use case"""
    
    print("\nğŸ† spaCy Model Comparison")
    print("=" * 60)
    
    models = {
        "en_core_web_sm": {
            "size": "~15MB",
            "vocab": "50K vectors",
            "accuracy": "Good",
            "speed": "Fast",
            "components": ["tok2vec", "tagger", "parser", "ner", "attribute_ruler", "lemmatizer"],
            "pros": [
                "âœ… Small size - perfect for deployment",
                "âœ… Fast processing - real-time responses", 
                "âœ… Good NER - handles abend codes well",
                "âœ… Parser included - sentence segmentation",
                "âœ… Balanced performance",
                "âœ… Standard choice for production"
            ],
            "cons": [
                "âš ï¸ Limited vocabulary",
                "âš ï¸ May miss complex technical terms"
            ],
            "recommendation": "ğŸŒŸ RECOMMENDED for your use case"
        },
        
        "en_core_web_md": {
            "size": "~40MB", 
            "vocab": "685K vectors",
            "accuracy": "Better",
            "speed": "Medium",
            "components": ["tok2vec", "tagger", "parser", "ner", "attribute_ruler", "lemmatizer"],
            "pros": [
                "âœ… Better word vectors",
                "âœ… Improved accuracy",
                "âœ… Better similarity matching",
                "âœ… More technical terms"
            ],
            "cons": [
                "âš ï¸ 3x larger than sm",
                "âš ï¸ Slower processing",
                "âš ï¸ More memory usage"
            ],
            "recommendation": "ğŸ”„ Consider if accuracy is critical"
        },
        
        "en_core_web_lg": {
            "size": "~560MB",
            "vocab": "685K vectors", 
            "accuracy": "Best",
            "speed": "Slower",
            "components": ["tok2vec", "tagger", "parser", "ner", "attribute_ruler", "lemmatizer"],
            "pros": [
                "âœ… Highest accuracy",
                "âœ… Best word vectors",
                "âœ… Excellent for complex NLP"
            ],
            "cons": [
                "âŒ Very large size",
                "âŒ Slow processing", 
                "âŒ High memory usage",
                "âŒ Overkill for chatbot"
            ],
            "recommendation": "âŒ NOT recommended for chatbot"
        },
        
        "en_core_web_trf": {
            "size": "~440MB",
            "vocab": "Transformer-based",
            "accuracy": "Excellent", 
            "speed": "Slowest",
            "components": ["transformer", "tagger", "parser", "ner", "attribute_ruler", "lemmatizer"],
            "pros": [
                "âœ… State-of-the-art accuracy",
                "âœ… Transformer architecture",
                "âœ… Best for complex understanding"
            ],
            "cons": [
                "âŒ Very large size",
                "âŒ Very slow processing",
                "âŒ Requires GPU for speed",
                "âŒ Overkill for simple tasks"
            ],
            "recommendation": "âŒ NOT recommended for real-time chatbot"
        }
    }
    
    for model_name, details in models.items():
        print(f"\nğŸ“¦ {model_name}")
        print(f"   Size: {details['size']}")
        print(f"   Vocabulary: {details['vocab']}")
        print(f"   Accuracy: {details['accuracy']}")
        print(f"   Speed: {details['speed']}")
        print(f"   Components: {', '.join(details['components'])}")
        
        print("   Pros:")
        for pro in details['pros']:
            print(f"     {pro}")
        
        print("   Cons:")
        for con in details['cons']:
            print(f"     {con}")
        
        print(f"   ğŸ“‹ {details['recommendation']}")
    
    return models

def test_model_performance():
    """Test actual performance with sample chatbot queries"""
    
    print("\nâš¡ Performance Testing")
    print("=" * 40)
    
    # Sample queries typical for your chatbot
    test_queries = [
        "S0C4 abend error",
        "Hello, I need help with password reset",
        "What is the relationship between Aspire and VTO?",
        "Job ABC123 is running for 3 hours",
        "Memory issue in production",
        "Good morning, can you help me?",
        "S0C7 data exception occurred"
    ]
    
    try:
        nlp = spacy.load("en_core_web_sm")
        print("âœ… Testing with en_core_web_sm")
        
        import time
        
        total_time = 0
        for query in test_queries:
            start_time = time.time()
            doc = nlp(query)
            end_time = time.time()
            
            processing_time = (end_time - start_time) * 1000  # Convert to ms
            total_time += processing_time
            
            entities = [(ent.text, ent.label_) for ent in doc.ents]
            tokens = len(doc)
            
            print(f"  ğŸ“ '{query}'")
            print(f"     â±ï¸  {processing_time:.2f}ms | ğŸ”¤ {tokens} tokens | ğŸ¯ {len(entities)} entities")
            if entities:
                print(f"     ğŸ“Š Entities: {entities}")
        
        avg_time = total_time / len(test_queries)
        print(f"\nğŸ“Š Average processing time: {avg_time:.2f}ms")
        
        if avg_time < 50:
            print("âœ… Excellent speed for real-time chatbot")
        elif avg_time < 100:
            print("âœ… Good speed for chatbot")
        else:
            print("âš ï¸ May be too slow for real-time responses")
            
    except OSError:
        print("âš ï¸ en_core_web_sm not available for testing")

def get_final_recommendation():
    """Provide final recommendation based on analysis"""
    
    print("\nğŸ¯ Final Recommendation for Aspire Support Chatbot")
    print("=" * 60)
    
    recommendation = {
        "recommended_model": "en_core_web_sm",
        "reasons": [
            "ğŸš€ Perfect size for web deployment (~15MB)",
            "âš¡ Fast processing for real-time responses",
            "ğŸ¯ Sufficient accuracy for abend code extraction",
            "ğŸ’¬ Good conversational understanding",
            "ğŸ”§ All needed components (NER, parser, tagger)",
            "ğŸ’¾ Low memory footprint",
            "ğŸ“¦ Easy to deploy and maintain",
            "âœ… Already working well in your current setup"
        ],
        "alternatives": {
            "If accuracy is critical": "en_core_web_md (but 3x larger)",
            "If size is extremely important": "Custom blank model with rules",
            "If offline deployment needed": "Download and bundle en_core_web_sm"
        },
        "installation": "python -m spacy download en_core_web_sm"
    }
    
    print(f"ğŸ† Recommended Model: {recommendation['recommended_model']}")
    print("\nğŸ“‹ Why this model is perfect for your chatbot:")
    for reason in recommendation['reasons']:
        print(f"  {reason}")
    
    print(f"\nğŸ“¦ Installation Command:")
    print(f"  {recommendation['installation']}")
    
    print(f"\nğŸ”„ Alternative Options:")
    for scenario, alternative in recommendation['alternatives'].items():
        print(f"  â€¢ {scenario}: {alternative}")
    
    print(f"\nâœ… Conclusion:")
    print(f"  Your current en_core_web_sm model is PERFECT for the Aspire Support")
    print(f"  chatbot. It provides the optimal balance of speed, accuracy, and size")
    print(f"  for your production support use case. No changes needed!")

def main():
    """Main function to run the complete analysis"""
    
    print("ğŸ¤– spaCy Model Recommendation Analysis")
    print("ğŸ¢ For: Aspire Support Chatbot")
    print("ğŸ“… Analysis Date: 2025-09-18")
    print("=" * 60)
    
    # Analyze requirements
    analyze_chatbot_requirements()
    
    # Compare models
    compare_spacy_models()
    
    # Test performance
    test_model_performance()
    
    # Final recommendation
    get_final_recommendation()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ Summary: en_core_web_sm is the optimal choice!")
    print("=" * 60)

if __name__ == "__main__":
    main() 
